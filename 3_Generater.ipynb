{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Generater.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWYid0hGIh/S8twx+9rmGL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newfull5/AI_Poet-KoGPT2/blob/master/3_Generater.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lbu_X17pLQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idc5kfNzpPIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/SKT-AI/KoGPT2.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKkHQPlmp2SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd KoGPT2 && pip install -r requirements.txt\n",
        "!cd KoGPT2 && pip install ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4vrUGkBp7DZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kogpt2.pytorch_kogpt2 import get_pytorch_kogpt2_model\n",
        "from gluonnlp.data import SentencepieceTokenizer\n",
        "from kogpt2.utils import get_tokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJWI3XmoqQW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.device_count():\n",
        "  PU = 'cuda'\n",
        "else:\n",
        "  PU = 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWqO4fu_qWyR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3b2605e5-36b8-4865-f2b4-7f2246272df5"
      },
      "source": [
        "PU"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLlWKPpxqXoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#토큰화와 인덱싱을해서 리턴하는 함수\n",
        "\n",
        "def dataset (file_path):\n",
        "  data = []\n",
        "  tokenizer = SentencepieceTokenizer(get_tokenizer())\n",
        "  f = open(file_path,'r',encoding='utf-8')\n",
        "\n",
        "  while True:\n",
        "    file = f.readline()\n",
        "\n",
        "    if not file:\n",
        "      break\n",
        "    line = tokenizer(file)\n",
        "    indexing_word = [vocab[vocab.bos_token]]+ vocab[line] + [vocab[vocab.eos_token]]\n",
        "    data.append(indexing_word)\n",
        "\n",
        "  f.close()\n",
        "\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKI_hmnnqjPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, vocab = get_pytorch_kogpt2_model()\n",
        "\n",
        "load_path = 'drive/My Drive/Colab Notebooks/KoGPT2_checkpoint/KoGPT2_checkpoint.tar'\n",
        "checkpoint = torch.load(load_path, map_location=torch.device(PU))\n",
        "\n",
        "model.to(torch.device(PU)) #모델 연산 유닛 설정\n",
        "torch.load(load_path, map_location=torch.device(PU))\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbvPvKKVql1G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d44fac3-61b6-4b8f-f9b9-9e11943eae72"
      },
      "source": [
        "Tokenizer = SentencepieceTokenizer(get_tokenizer())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6Kapq95tH59",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b469e2ca-dff7-410d-b9a9-c6b6e0cd30b9"
      },
      "source": [
        "sent =''\n",
        "while 1:\n",
        "\n",
        "  tmp_sent = input('다음...: ')\n",
        "  sent = sent+tmp_sent\n",
        "\n",
        "  toked = Tokenizer(sent)\n",
        "  count = 0\n",
        "  generated_text =''\n",
        "  input_size = 50\n",
        "\n",
        "  if len(toked) >1022:\n",
        "    break\n",
        "\n",
        "  while 1:\n",
        "    input_ids = torch.tensor([vocab[vocab.bos_token],]  + vocab[toked]).unsqueeze(0)\n",
        "    predicts = model(input_ids)\n",
        "    pred = predicts[0]\n",
        "    # print('predicts:', torch.argmax(pred, axis=-1).squeeze())\n",
        "    gen = vocab.to_tokens(torch.argmax(pred, axis=-1).squeeze().tolist())[-1]\n",
        "    if gen == '</s>':\n",
        "      print('to_tokens:',vocab.to_tokens(torch.argmax(pred, axis=-1).squeeze().tolist()))\n",
        "    if gen == '.' or count>input_size:\n",
        "      sent += gen.replace('▁', ' ')\n",
        "      generated_text += gen.replace('▁', ' ')\n",
        "      sent += '\\n'\n",
        "      generated_text += '\\n'\n",
        "      toked = Tokenizer(sent)\n",
        "      count =0\n",
        "      break\n",
        "      # print('to_tokens:',vocab.to_tokens(torch.argmax(pred, axis=-1).squeeze().tolist()))\n",
        "    # if count >= input_size:\n",
        "    #   break\n",
        "    sent += gen.replace('▁', ' ')\n",
        "    generated_text += gen.replace('▁', ' ')\n",
        "    # print(generated_text)\n",
        "\n",
        "    toked = Tokenizer(sent)\n",
        "    count += 1\n",
        "  print(generated_text)\n",
        "  generated_text=''\n",
        "print(sent)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "다음...: 몹시 졸리다\n",
            ".\n",
            "\n",
            "다음...: 왜 안나와\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', 's', '>', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', 's', '>', 's', '>', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '></', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '></', 's', '></', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '></', 's', '></', 's', '></', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '></', 's', '></', 's', '></', 's', '></', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '></', 's', '></', 's', '></', 's', '></', 's', '></', '</s>']\n",
            "to_tokens: ['▁나는', '▁높은', '음에', '.', '</s>', '온', '개와', '▁같이', '▁와서', '</s>', 'br', 'core', 'div', '>', 'f', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '>', 's', '></', 's', '></', 's', '></', 's', '></', 's', '></', 's', '></', '</s>']\n",
            " 같이 와서</s></s></s></s></s></s></s></s></s></s></s></s></s></s></s></s>                                  \n",
            "\n",
            "다음...: 같이 와서\n",
            " 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서 함께 와서\n",
            "\n",
            "다음...: 함께 오지마\n",
            ", 우리들, 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨\n",
            "\n",
            "다음...: 미치겠군\n",
            ", 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들 두레박을 깨뜨리고 우리들\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-d84b5c46391d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mtmp_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'다음...: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m   \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtmp_sent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul_dzgpvtgpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}