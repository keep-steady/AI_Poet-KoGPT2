{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Generater.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPa8z/UmZIeJ3D6cIQE8KVU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newfull5/AI_Poet-KoGPT2/blob/master/3.%20Generater.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lbu_X17pLQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idc5kfNzpPIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/SKT-AI/KoGPT2.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKkHQPlmp2SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd KoGPT2 && pip install -r requirements.txt\n",
        "!cd KoGPT2 && pip install ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4vrUGkBp7DZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kogpt2.pytorch_kogpt2 import get_pytorch_kogpt2_model\n",
        "from gluonnlp.data import SentencepieceTokenizer\n",
        "from kogpt2.utils import get_tokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJWI3XmoqQW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.device_count():\n",
        "  PU = 'cuda'\n",
        "else:\n",
        "  PU = 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWqO4fu_qWyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PU='cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLlWKPpxqXoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#토큰화와 인덱싱을해서 리턴하는 함수\n",
        "\n",
        "def dataset (file_path):\n",
        "  data = []\n",
        "  tokenizer = SentencepieceTokenizer(get_tokenizer())\n",
        "  f = open(file_path,'r',encoding='utf-8')\n",
        "\n",
        "  while True:\n",
        "    file = f.readline()\n",
        "\n",
        "    if not file:\n",
        "      break\n",
        "    line = tokenizer(file)\n",
        "    indexing_word = [vocab[vocab.bos_token]]+ vocab[line] + [vocab[vocab.eos_token]]\n",
        "    data.append(indexing_word)\n",
        "\n",
        "  f.close()\n",
        "\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKI_hmnnqjPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, vocab = get_pytorch_kogpt2_model()\n",
        "\n",
        "load_path = 'drive/My Drive/Colab Notebooks/KoGPT2_checkpoint/KoGPT2_checkpoint.tar'\n",
        "checkpoint = torch.load(load_path, map_location=torch.device(PU))\n",
        "\n",
        "model.to(torch.device(PU)) #모델 연산 유닛 설정\n",
        "torch.load(load_path, map_location=torch.device(PU))\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8brK2j4e79iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#모델 불러오기 코드 입니다\n",
        "from kogpt2.model.torch_gpt2 import GPT2Config, GPT2LMHeadModel\n",
        "\n",
        "save_path = 'drive/My Drive/Colab Notebooks/KoGPT2_checkpoint/'\n",
        "\n",
        "kogpt2_config = {\n",
        "\t\t\"initializer_range\": 0.02,\n",
        "\t\t\"layer_norm_epsilon\": 0.000025,\n",
        "\t\t\"n_ctx\": 1024,\n",
        "\t\t\"n_embd\": 768,\n",
        "\t\t\"n_head\": 12,\n",
        "\t\t\"n_layer\": 12,\n",
        "\t\t\"n_positions\": 1024,\n",
        "\t\t\"vocab_size\": 50000\n",
        "}\n",
        "\n",
        "checkpoint = torch.load(save_path+'KoGPT2_checkpoint.tar', map_location=PU)\n",
        "\n",
        "kogpt2model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\n",
        "\n",
        "kogpt2model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "kogpt2model.eval()\n",
        "\n",
        "kogpt2model.to(torch.device(PU))\n",
        "\n",
        "model = kogpt2model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbvPvKKVql1G",
        "colab_type": "code",
        "outputId": "c73c4c59-ab2b-449f-e895-3d6f65bedc4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Tokenizer = SentencepieceTokenizer(get_tokenizer())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0gdbf1R6-yU",
        "colab_type": "code",
        "outputId": "73347420-268f-4b56-9e4c-a9068fecf9a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sentence = '대학교'\n",
        "toked = Tokenizer(sentence)\n",
        "temp = []\n",
        "\n",
        "while True:\n",
        "  input_ids = torch.tensor([vocab[vocab.bos_token],] + vocab[toked]).unsqueeze(0)\n",
        "  pred = model(input_ids)[0]\n",
        "\n",
        "  gen = vocab.to_tokens(torch.argmax(pred, axis=-1).squeeze().tolist())\n",
        "  print(gen)\n",
        "  print(gen[-1])\n",
        "  gen = gen[-1]\n",
        "  \n",
        "  if '</s>' == gen:\n",
        "    break\n",
        "  sentence += gen.replace('▁', ' ')\n",
        "  toked = Tokenizer(sentence)\n",
        "\n",
        "print(sentence)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁그', '<unk>', '추', '련', '▁사']\n",
            "▁사\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n",
            "['▁그', '<unk>', '추', '련', '▁사', '샛', '▁']\n",
            "▁\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-2ad8584310a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbos_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoked\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kogpt2/model/torch_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels)\u001b[0m\n\u001b[1;32m    584\u001b[0m             \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m         )\n\u001b[1;32m    588\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kogpt2/model/torch_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, past, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             outputs = block(\n\u001b[0;32m--> 472\u001b[0;31m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_past\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer_past\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m             )\n\u001b[1;32m    474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kogpt2/model/torch_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, layer_past, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mln_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kogpt2/model/torch_gpt2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m         \u001b[0mh2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backward_hooks\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    556\u001b[0m             \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh7l0djy7A2i",
        "colab_type": "code",
        "outputId": "068fbd35-11e4-466f-f24b-517850de5f19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "vocab.eos_token"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'</s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTZ3UTo2__pH",
        "colab_type": "code",
        "outputId": "9ad1c99d-690d-4bd2-cde8-7dd0bd0364c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "gen"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'</s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp_UH3m1BJTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}