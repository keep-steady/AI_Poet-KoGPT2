{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3. Generater.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNFpcJKC3b0iBTv0/4tCgpX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newfull5/AI_Poet-KoGPT2/blob/master/3.%20Generater.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lbu_X17pLQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Idc5kfNzpPIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/SKT-AI/KoGPT2.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKkHQPlmp2SF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cd KoGPT2 && pip install -r requirements.txt\n",
        "!cd KoGPT2 && pip install ."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4vrUGkBp7DZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kogpt2.pytorch_kogpt2 import get_pytorch_kogpt2_model\n",
        "from gluonnlp.data import SentencepieceTokenizer\n",
        "from kogpt2.utils import get_tokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJWI3XmoqQW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if torch.cuda.device_count():\n",
        "  PU = 'cuda'\n",
        "else:\n",
        "  PU = 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWqO4fu_qWyR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PU='cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLlWKPpxqXoo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#토큰화와 인덱싱을해서 리턴하는 함수\n",
        "\n",
        "def dataset (file_path):\n",
        "  data = []\n",
        "  tokenizer = SentencepieceTokenizer(get_tokenizer())\n",
        "  f = open(file_path,'r',encoding='utf-8')\n",
        "\n",
        "  while True:\n",
        "    file = f.readline()\n",
        "\n",
        "    if not file:\n",
        "      break\n",
        "    line = tokenizer(file)\n",
        "    indexing_word = [vocab[vocab.bos_token]]+ vocab[line] + [vocab[vocab.eos_token]]\n",
        "    data.append(indexing_word)\n",
        "\n",
        "  f.close()\n",
        "\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKI_hmnnqjPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model, vocab = get_pytorch_kogpt2_model()\n",
        "\n",
        "load_path = 'drive/My Drive/Colab Notebooks/KoGPT2_checkpoint/KoGPT2_checkpoint.tar'\n",
        "checkpoint = torch.load(load_path, map_location=torch.device(PU))\n",
        "\n",
        "model.to(torch.device(PU)) #모델 연산 유닛 설정\n",
        "torch.load(load_path, map_location=torch.device(PU))\n",
        "\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8brK2j4e79iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#모델 불러오기 코드 입니다\n",
        "from kogpt2.model.torch_gpt2 import GPT2Config, GPT2LMHeadModel\n",
        "\n",
        "save_path = 'drive/My Drive/Colab Notebooks/KoGPT2_checkpoint/'\n",
        "\n",
        "kogpt2_config = {\n",
        "\t\t\"initializer_range\": 0.02,\n",
        "\t\t\"layer_norm_epsilon\": 0.000025,\n",
        "\t\t\"n_ctx\": 1024,\n",
        "\t\t\"n_embd\": 768,\n",
        "\t\t\"n_head\": 12,\n",
        "\t\t\"n_layer\": 12,\n",
        "\t\t\"n_positions\": 1024,\n",
        "\t\t\"vocab_size\": 50000\n",
        "}\n",
        "\n",
        "checkpoint = torch.load(save_path+'KoGPT2_checkpoint.tar', map_location=PU)\n",
        "\n",
        "kogpt2model = GPT2LMHeadModel(config=GPT2Config.from_dict(kogpt2_config))\n",
        "\n",
        "kogpt2model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "kogpt2model.eval()\n",
        "\n",
        "kogpt2model.to(torch.device(PU))\n",
        "\n",
        "model = kogpt2model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbvPvKKVql1G",
        "colab_type": "code",
        "outputId": "f58f42a6-5ee7-49ea-e4c9-fed650cf74a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Tokenizer = SentencepieceTokenizer(get_tokenizer())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0gdbf1R6-yU",
        "colab_type": "code",
        "outputId": "ac428706-3f16-42bd-8778-b09fc2728bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sentence = '진달래꽃'\n",
        "toked = Tokenizer(sentence)\n",
        "temp = []\n",
        "cnt = 0\n",
        "while True:\n",
        "  input_ids = torch.tensor([vocab[vocab.bos_token],] + vocab[toked]).unsqueeze(0)\n",
        "  pred = model(input_ids)[0]\n",
        "\n",
        "  gen = vocab.to_tokens(torch.argmax(pred, axis=-1).squeeze().tolist())\n",
        "  print(gen)\n",
        "  print(gen[-1])\n",
        "  gen = gen[-1]\n",
        "  cnt += 1\n",
        "\n",
        "  if cnt == 30:\n",
        "    break\n",
        "\n",
        "  if '</s>' == gen:\n",
        "    break\n",
        "  sentence += gen.replace('▁', ' ')\n",
        "  toked = Tokenizer(sentence)\n",
        "\n",
        "print(sentence)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "['▁', '그', '정', '레', '▁', '▁']\n",
            "▁\n",
            "진달래꽃                             \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sh7l0djy7A2i",
        "colab_type": "code",
        "outputId": "8f129528-ee31-437f-aec9-d85725b3ff1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab.eos_token"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'</s>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTZ3UTo2__pH",
        "colab_type": "code",
        "outputId": "c9b3f242-039d-4e55-89ba-491f81c7a07e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "gen"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'▁'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp_UH3m1BJTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "c243d868-9874-42f2-f8bd-a21f515c29d4"
      },
      "source": [
        "sentence"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2019 한해를 보내며                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1AkvP5i_XS8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "270c79ba-89c3-48db-e29e-8df585107d77"
      },
      "source": [
        "toked"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁', '2', '0', '1', '9', '▁', '한', '해', '를', '▁', '보', '내', '며']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJEoh6JmBHkp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}